{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topics\n",
    "\n",
    "## 1. Quick PCA review: The difference between \n",
    "\n",
    "### pca.fit() \n",
    "### pca.transform()\n",
    "### pca.fit_transform()\n",
    "\n",
    "## 2. Support Vector Machine (SVM)\n",
    "\n",
    "## 3. SVM Applied to Handwritten Digit Recognition\n",
    "\n",
    "## 4. The meaning of gamma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC: Support Vector Classification\n",
    "## In sklearn.svm.SVC() the default kernel is RBF\n",
    "## For kernel parameters, see\n",
    "## http://scikit-learn.org/stable/modules/svm.html#svm-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> float64 (1797, 64)\n",
      "<class 'numpy.ndarray'> float64 (1797, 8, 8)\n",
      "<class 'numpy.ndarray'> int64 (1797,)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "''' Initial Imports'''\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# ***use seaborn plotting style defaults\n",
    "# import seaborn as sns; sns.set()\n",
    "\n",
    "from sklearn import decomposition\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "\n",
    "#********************* KEY IMPORT OF THIS LECTURE********************************\n",
    "from sklearn import svm\n",
    "\n",
    "\n",
    "# loading handwritten digits\n",
    "dig_data = load_digits()\n",
    "X = dig_data.data\n",
    "# y: the values of the digits, or \"ground truth\"\n",
    "y = dig_data.target\n",
    "dig_img = dig_data.images\n",
    "print(type(X), X.dtype, X.shape)\n",
    "print(type(dig_img), dig_img.dtype, dig_img.shape)\n",
    "print(type(y), y.dtype, y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's explore the documentation for SVC \n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "\n",
    "## and the attributes:\n",
    "\n",
    "- ### support\\_ : array-like, shape = [n\\_SV]\n",
    "Indices of support vectors.\n",
    "\n",
    "\n",
    "- ### support\\_vectors\\_ : array-like, shape = [n_SV, n_features]\n",
    "Support vectors.\n",
    "\n",
    "- ### n\\_support\\_ : array-like, dtype=int32, shape = [n_class]\n",
    "Number of support vectors for each class.\n",
    "\n",
    "- ### dual\\_coef\\_ : array, shape = [n_class-1, n_SV]\n",
    "dual\\_coef\\_ : array, shape = [n_class-1, n_SV]\n",
    "Coefficients of the support vector in the decision function. For multiclass, coefficient for all 1-vs-1 classifiers. The layout of the coefficients in the multiclass case is somewhat non-trivial. See the section about multi-class classification in the SVM section of the User Guide for details.\n",
    "\n",
    "    --> These can be converted to the Langrange multipliers (i.e., the weights; except here, with labels mixed in)\n",
    "    \n",
    "- ### intercept_ : array, shape = [n_class * (n_class-1) / 2]\n",
    "Constants in decision function.  \n",
    "\n",
    "    --> That is, the b! (I have thought much about the shape yet -- need to do that.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying SVM Handwritten Digit Recogntion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters to specify:\n",
    "\n",
    "- ### kernel: The default is 'rbf'.  For other kernels, see\n",
    "\n",
    "    ### http://scikit-learn.org/stable/modules/svm.html#kernel-functions\n",
    "\n",
    "- ###  Setting C: C is 1 by default and itâ€™s a reasonable default choice. If you have a lot of noisy observations you should decrease it. It corresponds to \"regularize\" the estimation: The parameter C, common to all SVM kernels, trades off misclassification of training examples against simplicity of the decision surface. A low C makes the decision surface smooth (ignores noise), while a high C aims at classifying all training examples correctly (but maybe giving noise too much weight). [We will addres the issue of overfitting in Computational Physics II.]\n",
    "\n",
    "- ### If data for classification are unbalanced (e.g. many positive and few negative), set class_weight='balanced' and/or try different penalty parameters C.\n",
    "\n",
    "- ### (Particular to RBF) gamma: it defines how much influence a single training example has. The larger gamma is, the closer other examples must be to be affected.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> float64 (1797, 64)\n",
      "<class 'numpy.ndarray'> int64 (1797,)\n",
      "Xtrain.shape, ytrain.shape (1796, 64) (1796,)\n",
      "Xtest.shape, ytest.shape (1, 64) ()\n",
      "(1796, 10)\n",
      "(1, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAABA5JREFUeJzt3cFNI1kYRtHyiD2E4AxwCkRghwAZdAgmA8jEZEAIJgOHQAY1CbSEWj3+GV3OWZfqKyNdvQ3S26zrugBN/3z3BwDXI3AIEziECRzCBA5hAocwgUOYwCFM4BB2c6X3+ve4/8D7+/vY1uFwGNva7XZjW5N/w2+w+eoBJziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCrnV1UdL5fB7de3h4GNu6vb0d27pcLmNbP50THMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmGuLvoDp9NpdO/+/n5s63A4jG09Pz+Pbf10TnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzC3E32B379+jW6t91ux7Ymf9t+vx/b+umc4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAjbrOt6jfde5aW/8/n5OTW1vLy8jG0ty7KcTqexrcvlkty6u7sb2/oGm68ecIJDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAh7Oa7P+BvHY/Hsa3X19exrWmT1yTFrxP6X3GCQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIWyzrus13nuVl/7O+XyemloeHx/HtpZlWT4+Pkb3puz3+7Gtp6ensa1lmf1ty7JsvnrACQ5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUPYzXd/wN/a7XZjW5P3oE3vHY/Hsa23t7exre12O7a1LON3k33JCQ5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAoewzbqu3/0NwJU4wSFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAoewfwHIOEq1kOcRngAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10b173a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "''' \n",
    "Now, we get the first \"2\" right!\n",
    "\n",
    "The first \"5\" is still trouble, \n",
    "but even human can't necessarily tell that \"5\"!  \n",
    "\n",
    "'''\n",
    "dig_data = load_digits()\n",
    "X = dig_data.data\n",
    "y = dig_data.target\n",
    "# This is basically each array in X\n",
    "# getting reshaped into (8, 8).\n",
    "dig_img = dig_data.images\n",
    "\n",
    "print(type(X), X.dtype, X.shape)\n",
    "print(type(y), y.dtype, y.shape)\n",
    "\n",
    "select_idx = 2\n",
    "# select_idx = 5\n",
    "\n",
    "# ********************************Separating training data from testing data****************\n",
    "Xtrain = np.delete(X, select_idx, axis = 0)\n",
    "ytrain = np.delete(y, select_idx)\n",
    "\n",
    "# if you don't do .reshape(1, -1), you get a warning.\n",
    "# B/c the data argument for classifier has to be an array,\n",
    "# even if it's a one-element array.\n",
    "Xtest = X[select_idx].reshape(1, -1)\n",
    "test_img = dig_img[select_idx]\n",
    "ytest = y[select_idx]\n",
    "\n",
    "print('Xtrain.shape, ytrain.shape', Xtrain.shape, ytrain.shape)\n",
    "print('Xtest.shape, ytest.shape', Xtest.shape, ytest.shape)\n",
    "\n",
    "plt.figure(figsize = (4, 4))\n",
    "plt.imshow(test_img, cmap = 'binary')\n",
    "plt.grid('off')\n",
    "plt.axis('off')\n",
    "\n",
    "\n",
    "# ************************************* The PCA Section ********************************\n",
    "n_comp = 10\n",
    "\n",
    "pca = PCA(n_comp)  \n",
    "\n",
    "# finding pca axes\n",
    "pca.fit(Xtrain)\n",
    "# projecting training data onto pca axes\n",
    "Xtrain_proj = pca.transform(Xtrain)\n",
    "# projecting test data onto pca axes\n",
    "Xtest_proj = pca.transform(Xtest)\n",
    "\n",
    "print(Xtrain_proj.shape)\n",
    "print(Xtest_proj.shape)\n",
    "\n",
    "\n",
    "# ************************************* The SVM Section ********************************\n",
    "\n",
    "# instantiating an SVM classifier\n",
    "clf = svm.SVC(gamma=0.001, C=100.)\n",
    "\n",
    "# apply SVM to training data and draw boundaries.\n",
    "clf.fit(Xtrain_proj, ytrain)\n",
    "# Use SVM-determined boundaries to make\n",
    "# a prediction for the test data point.\n",
    "clf.predict(Xtest_proj)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breakout:\n",
    "## 1. Turn the above into a function\n",
    "## classify_dig_svm(X, y, dig_img, select_idx, n_comp = 10, plot_test_img = False)\n",
    "## where\n",
    "- ### X: data\n",
    "- ### y: targets (labels, or \"ground truth\")\n",
    "- ### select_idx: the index of the test data point\n",
    "- ### dig_img: 2D arrays of the digit image that corresponds to select_idx\n",
    "- ### plot_test_img: plot the above image, if True.\n",
    "- ### n_comp: how many PCA components to use\n",
    "- ### returns the prediction\n",
    "\n",
    "## 2. Test this function on select_idx = 0, 1, and 2.  One at a time.\n",
    "\n",
    "## 3. Write a main program that does the \"leave-one-out\" test first for 50 images, just as we did in last class, 10 components; then move up to 20 components.  Compute the success rate in each case.\n",
    "\n",
    "## 4. Do the \"leave-one-out\" test for 500 images for 10 and then 20 components.  Compute the success rate for each case (takes about 1 min).\n",
    "\n",
    "## The success rates for all 1797 images with 20 (or 30) components are similar to 500 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def classify_dig_svm(X, y, dig_img, select_idx, n_comp = 10, plot_test_img = False):\n",
    "    Xtrain = np.delete(X, select_idx, axis = 0)\n",
    "    ytrain = np.delete(y, select_idx)\n",
    "    \n",
    "    Xtest = X[select_idx].reshape(1, -1)\n",
    "    test_img = dig_img[select_idx]\n",
    "    ytest = y[select_idx]\n",
    "    \n",
    "    if plot_test_img:\n",
    "        plt.figure(figsize = (4, 4))\n",
    "        plt.imshow(test_img, cmap = 'binary')\n",
    "        plt.grid('off')\n",
    "        plt.axis('off')\n",
    "    \n",
    "    # PCA\n",
    "    pca = PCA(n_comp)\n",
    "    pca.fit(Xtrain)\n",
    "    Xtrain_proj = pca.transform(Xtrain)\n",
    "    Xtest_proj = pca.transform(Xtest)\n",
    "    # print(Xtrain_proj.shape)\n",
    "    # print(Xtest_proj.shape)\n",
    "\n",
    "    # SVM\n",
    "    clf = svm.SVC(gamma=0.001, C=100.)\n",
    "    clf.fit(Xtrain_proj, ytrain)\n",
    "    return clf.predict(Xtest_proj)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success rate for 50 images with 10 components: 96.0%\n",
      "Success rate for 50 images with 20 components: 96.0%\n"
     ]
    }
   ],
   "source": [
    "dig_data = load_digits()\n",
    "X = dig_data.data\n",
    "y = dig_data.target\n",
    "dig_img = dig_data.images\n",
    "select_idx = 2\n",
    "n_comp = 10\n",
    "\n",
    "# classify_dig_svm(X, y, dig_img, 0, n_comp = n_comp, plot_test_img = True)\n",
    "# classify_dig_svm(X, y, dig_img, 1, n_comp = n_comp, plot_test_img = True)\n",
    "# classify_dig_svm(X, y, dig_img, 2, n_comp = n_comp, plot_test_img = True)\n",
    "\n",
    "\n",
    "sample_size = 50\n",
    "\n",
    "def test(X, y, dig_img, n_comp, size):\n",
    "    correct = 0\n",
    "    for i in range(size):\n",
    "        result = classify_dig_svm(X, y, dig_img, i, n_comp = n_comp)\n",
    "        if result == y[i]:\n",
    "            correct += 1\n",
    "\n",
    "    rate = correct / size * 100\n",
    "    print(\"Success rate for {} images with {} components: {}%\".format(size, n_comp, rate))\n",
    "    \n",
    "test(X, y, dig_img, 10, 50)\n",
    "test(X, y, dig_img, 20, 50)\n",
    "# test(X, y, dig_img, 10, 500)\n",
    "# test(X, y, dig_img, 20, 500)\n",
    "# test(X, y, dig_img, 20, 1797)\n",
    "# test(X, y, dig_img, 30, 1797)\n",
    "\n",
    "# Results\n",
    "\n",
    "# Success rate for 50 images with 10 components: 96.0%\n",
    "# Success rate for 50 images with 20 components: 96.0%\n",
    "# Success rate for 500 images with 10 components: 98.2%\n",
    "# Success rate for 500 images with 20 components: 99.0%\n",
    "# Success rate for 1797 images with 20 components: 99.1652754590985%\n",
    "# Success rate for 1797 images with 30 components: 99.1652754590985%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of week 15-1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
