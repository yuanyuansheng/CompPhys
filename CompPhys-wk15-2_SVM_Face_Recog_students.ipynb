{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topics\n",
    "\n",
    "## 1. PCA Applied to Face Images and \"Whitening\" \n",
    "## 2. PCA and SVM on Face Recognition\n",
    "## 3. The Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "''' Initial Imports'''\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\* \n",
    "# Place the data set on google drive \n",
    "# for some reason, it takes a long time to download \n",
    "# the data. \n",
    "# \\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\n",
    "\n",
    "## To Downloading Faces (233MB)\n",
    "\n",
    "## (This takes a while and you should start now):\n",
    "\n",
    "http://vis-www.cs.umass.edu/lfw/lfw-funneled.tgz \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "height and width of images: 50 37\n",
      "X.shape (1288, 1850)\n",
      "target_names.shape (7,)\n",
      "target_names ['Ariel Sharon' 'Colin Powell' 'Donald Rumsfeld' 'George W Bush'\n",
      " 'Gerhard Schroeder' 'Hugo Chavez' 'Tony Blair']\n",
      "Total dataset size:\n",
      "n_samples (number of faces): 1288\n",
      "n_features (number of pixels): 1850\n",
      "n_classes (number of people): 7\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "sklearn face data base\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from sklearn import datasets\n",
    "\n",
    "###############################################################################\n",
    "# Download the data, if not already on disk and load it as numpy arrays\n",
    "\n",
    "lfw_people = datasets.fetch_lfw_people(min_faces_per_person=70, \\\n",
    "                                       resize=0.4)\n",
    "\n",
    "# introspect the images arrays to find the shapes (for plotting)\n",
    "n_samples, h, w = lfw_people.images.shape\n",
    "print('height and width of images:', h, w)\n",
    "\n",
    "# The images in X have been collapsed into a 1D array\n",
    "# just like for the handwritten digits\n",
    "X = lfw_people.data\n",
    "\n",
    "# X.shape[0] tells you the number of images (faces);\n",
    "# this is the same as n_samples ahove\n",
    "# X.shape[1] gives the number of pixels for each image\n",
    "# or, \"features\"\n",
    "\n",
    "print('X.shape', X.shape)\n",
    "n_features = X.shape[1]\n",
    "\n",
    "\n",
    "# the label/target to predict is the id of the person -- y is an integer\n",
    "y = lfw_people.target\n",
    "# target_names are actually names\n",
    "target_names = lfw_people.target_names\n",
    "print('target_names.shape', target_names.shape)\n",
    "print('target_names', target_names)\n",
    "\n",
    "# n_classes gives the number of people \n",
    "# Different from the number of faces (n_samples)!!\n",
    "n_classes = target_names.shape[0]\n",
    "\n",
    "print(\"Total dataset size:\")\n",
    "print(\"n_samples (number of faces): {0}\".format(n_samples))\n",
    "# n_features = 1850, which is 50x37, the dimension of the images.\n",
    "print(\"n_features (number of pixels): {0}\".format(n_features))\n",
    "print(\"n_classes (number of people): {0}\".format(n_classes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Whitening\"\n",
    "\n",
    "## Breakout Exercise:\n",
    "\n",
    "- ## Do PCA on the first 500 images.  Use only 4 components\n",
    "- ## Print out the PCA components (eigenvectors)\n",
    "- ## Print out the PCA variances (eigenvalues)\n",
    "- ## Calculate yourself the variance of along the 0th and 1st PCA axes\n",
    "\n",
    "## Turn on whitening in your PCA instantiation: \n",
    "\n",
    "          whiten = True\n",
    "          \n",
    "## Run the cell again -- can you tell what changed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvector: [[-0.00171167 -0.00188718 -0.00477223 ..., -0.01426285 -0.01422086\n",
      "  -0.01390798]\n",
      " [-0.0254456  -0.02447076 -0.02559022 ...,  0.03231155  0.0320539\n",
      "   0.03345388]\n",
      " [-0.02074062 -0.01764376 -0.01742082 ..., -0.04799965 -0.041061\n",
      "  -0.03706346]\n",
      " [-0.03556924 -0.03758161 -0.03788461 ..., -0.02902506 -0.03130636\n",
      "  -0.02524168]]\n",
      "variances: [ 506687.5625    389540.4375    194728.296875  153637.6875  ]\n",
      "505674.0\n",
      "388761.0\n"
     ]
    }
   ],
   "source": [
    "x500 = X[:500, ]\n",
    "# print(x500.shape)\n",
    "pca = PCA(4)\n",
    "# pca = PCA(4, whiten = True)\n",
    "x_trans = pca.fit_transform(x500)\n",
    "# x_trans = pca.fit(x500)\n",
    "print(\"eigenvector:\", pca.components_)\n",
    "print(\"variances:\", pca.explained_variance_)\n",
    "# print(pca.components_[0].shape)\n",
    "variance0 = np.var(x_trans[:, 0])\n",
    "variance1 = np.var(x_trans[:, 1])\n",
    "print(variance0)\n",
    "print(variance1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussing the solution\n",
    "\n",
    "- ### The importance of whiten = True\n",
    "    \n",
    "- ### To understand why this helps: \n",
    "\n",
    "    ### Imagine just doing this with just 2 PCA components.  With whitening, in that 2D PCA space, the variance in each PCA direction is 1.  Then you expect to see clusters that are similar in extent in either direction -- meaning they would apear more circular.  This makes it easier to draw boundaries between clusters.\n",
    "\n",
    "- ### This is a helpful resource \n",
    "\n",
    "    ### To see what whitening does:\n",
    "\n",
    "    ### From http://ufldl.stanford.edu/tutorial/unsupervised/PCAWhitening/\n",
    "\n",
    "    ### Look under the Section \"Whitening\", subsection \"2D example\"\n",
    "    \n",
    "   ### Can plot the data in the 2D space of the first two PCA components, with and without whitening to show the effect -- either for the digit data (not much difference) or the face data \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breakout Exercise:\n",
    "\n",
    "### Write a function, plot_faces() [similar to plot_dig()] to plot and label the faces with their correct names. (You may consider expanding the functionality of plot_faces() a bit so that it can label each image with both the correct names and predicted names.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVcAAAHYCAYAAAD516sVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3XuQXnd93/HP17rsaqXVri6WJVuK\n7fpWA00D9BZIqYEEQjpNm4GWZkIJbQotU9ppm7QpZNomk5Q0QzuhTQqTzDCBEEgZOi0k09ACTRhi\nJs0FbAJJMQZi3SzZumsv0grZp3+cR7Ber87383h/35XB79eMxvZzfv6d37k8X5199vP7PdF1nQAA\nbV13rQcAAN+MKK4AUIDiCgAFKK4AUIDiCgAFKK4AUIDiChSLiHsioouI113rsWD9UFxRKiLePSos\nu6+y/XWj7a9a77GtVUTcGRHviIgvRMRCRFyIiC9GxC9GxJ+/1uPDtbXxWg8A+EYUET8k6Z2SLkr6\nVUn3S7os6U5Jr5T0+oh4dtd1f3ztRolrieIKjCkivlPSL0r6Y0kv77ru4RXb3yzpH1+LseHpg48F\nTMt+fH1JRPxIRHw5IpZGPwb+4CrtXx0RvxYRh0btTkbEhyLiW1dp+1BEfCIi/mxEfDwi5iPi0Yj4\nDxGxMSImR/9+NCIuRsQnI+LuVfqZiIi3RMQfjdqdjYhfj4jnVp2XCsvO9T2rbPtERDy0yutvjIgH\nRsf9xYh409X6iYhbIuK9EfHI6Np8OSLeGhFT5hB/RlJIevXKwipJXddd7rruZ1d7ao2Ivzu6PksR\ncTAi/uUqbV4WER+IiK+MPmo4GxEfjYi/sqLdByLi0mofuUTEXaNjf/uK118dEfdGxFxELEbE7678\nSGbZRzmr/jHP0TMeT67je6ukLZJ+QdKSpDdKendEfKnruk8ta/cmSafVP+Ecl3SbpDdI+lREPK/r\nugdX9Ltf0sckfUDSf5P0Mkk/LOkxSc8e7fPfS9ot6UckfSgi7u667nFJiohNkv6XpBdIeq+kn5c0\nI+n1o32+qOu6Pxg6sFEfM+6J6LrupNtW0s6IWO31bWP0saqI+FH15+Yzkt4iaUrSv5B0YpW2N0v6\nPfXH+U5JX5R0j6Q3S3phRLy067rLA/u6VdLzJP32U/iR/x9KukHSuySdlfQaST8TEUe6rnv/snav\nk7RT0i9LOiLpJkl/X9L/iYgXd13326N275H0tyT9bfXXe7nXLmtzZew/JenH1N8n/1rS45K+T9IH\nI+JNXdf9l1HTX5D08RX97ZL0NklnxjzmZ66u6/hj/FF/w3eS7pO0ednrN6kvsr+6ov3WVfq4e9T2\nHStef2jU999c8fqn1b8BPiwplr3+T0btX77stX+28rXR69slHZL0CeMY7xn1Yf0xz9u7zf5etcq5\nvmeV/j4h6aFl/71T0gVJfyhpctnreyWdW9mPpPeNXvueFf2+bfT6DyXH89dG7f7zGPfOlfP6sKTZ\nZa9Pqf8L4HeMe+cGSScl/cay1zZIOibp91a0DUkHJf3hsteeNxrDW1fp+0OSzkuavsr4N0v65Og8\nf/u1fB9+I/3hyXV87+i67tKV/+i67mhEfFHSHcsbdV23IEnRP65Nq79BT0h6QNJfXKXfo13XfXDF\na/eqf1P8XDe6y0euPLncIel/j/79NZK+IOnTq/yY+DFJPxgRW7quuzBwbJ+V9F0D29filerfwCu9\nTP1T5lP1XZImJb2z67qLV17suu54RLxP/U8WkqSIuE7S90q6r+u631jRz09L+ufqn+TeNbC/7aN/\nrnYsmV/quu7ssjEuRsT/lfTtyxtduXdGY94maUL9TzC/K+kvLWv32OgYfzgi/nTXdV8YbbpH0reo\n/wnnih9QX1zfs8r98WuS/vpoHB9dZdzvkvQdkr6/67rf8Q/3mY3iOr6vrPLaKUk3L39h9DnnT6q/\n0beuaP8nq/Sx2mtnrrLtyuu7lr12t/qPDp70o/AyuyUdvtrGruvO6Mk/DrbyyW6VjxEiYv8a+711\n9M8HVtm28rXr1X8M8UcrG3Zddzoijkn6U8n+rhTV6XEGOXK1e2f5dVRE3Cbp30l6uaTZlUNd8d/v\nUf/x0WvVfySi0b8/pv4p/Yq71T/RfkFXd8PKFyLi36r/i/vfdF33gYH/FytQXMf32FVe/9oHihHx\nLep/jDqvvsA+IGlB/Rvj7Vr9c8ar9Wvtc/Tvn1P/9HU1Q4VXEbFZ/Y/Zlq7rjrttxzT0S5OV9+yq\nH+RexThtr+bzo38+lV8SDl1jSV97Uv2k+r+Q367+ms6p/3jozZJesrx913Wfi4j7Jb0mIn5M/V+w\nr5T00RXXJ9Sf11cMjOMJf+lExA9I+nFJ7+267iezseOJKK41vk99Af3erut+a/mGiNil/nPX1h5U\n/2T2m93ol1xPwQsk/Vba6utaFKvVnB79c7VCf6ukry777ytP9XdJ+s0Vbe9a8d+Pqi9Uz17ZaUTs\nkLRPfV71qrqu+5OIuE/9L7+W/yjeyksl3Sjp73Vd90srxvhTV/l/3iPpZyW9WP0xTGvZL7JGHpT0\n3ZIOdV33/7JBRMR3qP844F71v0zDmIhi1bjyZPCE4hMRr1f/i5YKvzzqe9Un14h40o98q7jymav7\np8oXR//8zuUvRsT3qy88y31Mo9RGREwua7tX/eeMXzP6S+fXJT03Ir57RT//Sv374X8Y4/vR0T//\n62g/TxARGyLin0bEs4y+VrravfMyrf5ZvSS9X/0EhteO/pxT/0vQ5d47+udbI2LDKmPes+zfb1P/\nS64jkv7G8t8xwMeTa42PSFqU9N6I+Hn1n5G+UNL3SPqyas77f1Jf8N4WES9R/xR3Xv0vNl6qfibR\ni4c6KP7M1dZ13QMR8XFJ/2D0C8H7JX2b+p8IviRp07K2pyLiJ9RH5D4VEb+i/rfwb1BfpP+cnvgx\nw1vUn6cPRcQ7Rv29SNKr1f84vvKJb7XxfSwi3qA+yvVARCyfoXW7+h/Lb5P0nKdw+Peqj+79x4i4\nRX2B+zZJf0f9RwR/ZpXxPBoRH5H0KvW/3HvX8l/ujdr8/ujz05+QdH9EfFB9emGfpOervzc3j5q/\nX/3nwO+U9IqVEbqu637lKRzXM8+1jit8o/zRGPGg0WsvUv9GmVOfafyf6t9sq7V9SKtEpdR/3tVJ\numXF67eMXv/xFa9vVB/T+n31n/EuqP9x8H2SXnaNztu7R2PdnZzXV614fa+kD6r/C2Je/V9Yd692\n/kbt/5H6Yro0OuY3qZ8l1Un6Cyva3qr+Se5RSZfU/6LprZKmxjy2u/T1rOyi+r/AHlCfE33usnb3\njMbxuqudnxWvfav6LOqZ0f3zCUl/ebW2y/6fV+rrsbYXDoz5r6pPmJwenavDo3P7xhX345oiePzp\n+uwk8M0oIn5OfZG9seu6Y9d6PHhmobjiG15ETHYrfgyOiH3qY0eHuq570o/SQDU+c8U3g3si4m2S\n/rv6zyhvUT/td5v6X1QB647iim8GX1L/i8LXq/9FzEVJfyDpp7uuu+a/oMMzEx8LAECBcZ9c11yJ\nH388z7fPz8+nbe69997B7Z/73OfSPm699da0zd69a4+lXr581UWWvuYqK0Y9QXbunP089lg6SUhf\n/epX0zbZWK67Lo9QO3+xr9cxZ/04963Txhnv0tLwHBOnjxbjda5PNlZJWlxcHNx+8mS+uNrx4/lk\nwIcfftLqj09y9uzZwe0LCwuD2yXp2LFj1uQZJhEAQAGKKwAUoLgCQAGKKwAUoLgCQAGKKwAUoLgC\nQAGKKwAUaD79NQsmOwH1gwcPpm0++9nPDm7ftGnT4HZJmprKv6Z+vcLY68U5HmdCQ9bGCbq3mERw\n6VK+jnOLcL8z1lZtNmx40lrWT+Acj7Of7Bq2mjiRjcUZa6uJOFkbZ/KLiydXAChAcQWAAhRXAChA\ncQWAAhRXAChAcQWAAhRXACgwVs71/PnzaZtsYdwTJ06kfXzkIx9J23z6058e3P6KV7wi7aNVztXJ\n4GVa5Ota5R9baDWW7Nw6C2G3yGs6+2l1brN+nDxni/20WGTc4RyPk2d2MvQtxuviyRUAClBcAaAA\nxRUAClBcAaAAxRUAClBcAaAAxRUAClBcAaDAWJMIPvOZz6RtHn744cHtR48eTfu477770jaTk5OD\n23ft2pX24QSTHVkYu9UCvOu1KPd6LS7dYiytgu4tAvXOeWuh1ViyfloF97M2S0tLaR8XL15M2zj9\nZG2cPlw8uQJAAYorABSguAJAAYorABSguAJAAYorABSguAJAAYorABQYaxLBhz/84bTNuXPnBrfP\nz8+nfThtXvCCFwxu37gxPzQnXO5MAMj2tWHDhrQPR7Ziu3PMzlicwHYWUnfOW4tvCHBWsXeOucUE\nAGcsLSY9tJo4kYX7W63sn91PzjecOOF+Z+JKi0kpLp5cAaAAxRUAClBcAaAAxRUAClBcAaAAxRUA\nClBcAaDAWDnXI0eOpG2ynJiTody2bVvaZv/+/WmbTKtcaNamVc6yxaLbTi5x8+bNaZsW2V1nMeYs\nO7peC5G3WEDcbdNiLE5eM2vjjNXZT3adnVy7k7l1xrJeC9tLPLkCQAmKKwAUoLgCQAGKKwAUoLgC\nQAGKKwAUoLgCQAGKKwAUGGsSgbNgbRYYdoLjt99+e9pmdnZ2cPumTZvSPpxJBM4CvFkbJ/TdYj8O\nJ4ztBKmd85txQurZfpxz69xz2Vic89ZqcekW+1mv92qLe9sJ/zvH7Lw/sskvLRZNv4InVwAoQHEF\ngAIUVwAoQHEFgAIUVwAoQHEFgAIUVwAoQHEFgAJjTSKYm5tL22RhXyd8vmfPnrRNNgFgYmIi7SNb\n5V7yAs4tOGPJOGN19uN8y0A20cAJoDvjza6z880WLVbld0L5rVbub9GHE7rPrlGLCQ8O55svWn1D\nQHY/tXgfXsGTKwAUoLgCQAGKKwAUoLgCQAGKKwAUoLgCQAGKKwAUoLgCQIHmkwiygHP2DQKStH37\n9rRNFnR3gvBOSNoJFWcroLf4BgEpD4Y7q6i3+vaFCxcuDG53gu7OfrJJAtk4JG8CQItwf6sJGtl9\n2ercZuNtFahvcf87563FtxU4+3Hx5AoABSiuAFCA4goABSiuAFCA4goABSiuAFCA4goABcbKuc7P\nz6dtsgzejh070j5mZmbSNlle01ms2cnfOW2yY26Vc12v/TjnzsmOtuhjYWFhcLuTVXayvdki7k7+\ncb3uOSfb2+JecM6bI1sMe8uWLWkfziL7zoLa2XlpuUA4T64AUIDiCgAFKK4AUIDiCgAFKK4AUIDi\nCgAFKK4AUIDiCgAFxkoJtwiOT01NpW22bt2atskWUXYWFHZCx86Cwdkiva0WN844x+Ncw+zcSm0m\nNDiLG2eygLrknZfseJw+nKC7cy9kExaccH/LMPwQZ3LFxMTE4HZnYpEzccKZ5HT+/PnB7c5EEBdP\nrgBQgOIKAAUorgBQgOIKAAUorgBQgOIKAAUorgBQgOIKAAXaLDW+vMMk4HzjjTemfTjB5Lm5ucHt\nTojamSDgtHn88ccHtzvBcadNNhYnXO4E95022Vic0H0LzqSI7Po4bZz7ydmPw7kX1oMzEcR5f2QT\nPWZnZ9M+nJrgjOWhhx4a3H7mzJm0DxdPrgBQgOIKAAUorgBQgOIKAAUorgBQgOIKAAUorgBQYKyc\nq5Oj3LZt2+D2AwcOpH04Ocss3+j00Sp/muUBnfyds0hvth8nW+pkF51jzjKdLa6h08bJn2aLNUv5\nNWqVPW2xQLtzzC0Wy3bu2xb7cRYZ37lzZ9rGGW+Wlz148GDah4snVwAoQHEFgAIUVwAoQHEFgAIU\nVwAoQHEFgAIUVwAoQHEFgAJjTSJwwth79+4d3H799denfSwsLKRtskVtnXCzE+h2wvBZMN8JSS8u\nLqZtsiC7M0HACe7Pz8+nbc6ePTu4/fz582kfzrnNzt2OHTvSPmZmZtI22eSXbMFnyTu3Fy9eTNtk\n966zH+fenpycHNzuTBpqsUC4sxC2I7uGkrRv377B7c65dfHkCgAFKK4AUIDiCgAFKK4AUIDiCgAF\nKK4AUIDiCgAFKK4AUGCsSQROADqbaHDy5Mm0j1OnTqVtshXDnZX9Z2dn0zbbt29P22Rh7KmpqbQP\nZxJBNknAuT5Z+F+Szp07t+Y2zvnPzpuUTzpxVqh3rnM2WcEJujuTbJzrnE2icYL7zoSSbLKCs7K/\n08aZjNCiD2eix/T09OD2G2+80R5ThidXAChAcQWAAhRXAChAcQWAAhRXAChAcQWAAhRXACgwVgAt\nW6xZyhfpPX36dNrHI488krbJFst2Fnw+evRo2sZZjHnPnj2D23fv3p32sXXr1rRNluNzMofOeXEy\nktl1bpFhlaRdu3YNbneypc6i3FkbZ8FzZ4Fqp012nZ3r4xxzdr8495OT/3WOuQVnP9l4nVy7iydX\nAChAcQWAAhRXAChAcQWAAhRXAChAcQWAAhRXAChAcQWAAmNNIpiZmUnbZOFxJ6TrLHqbBdBbLPgs\neaH7bAFqJ9y8ZcuWNbdxzpuz0LIzWSTrxwm6OwtqP/jgg4PbL1y40GQ/2cLRzr3vTIpw7v9scXVn\n4Wgn3N+CM5ZsAoYzWcG5bx3ZeXEmv7h4cgWAAhRXAChAcQWAAhRXAChAcQWAAhRXAChAcQWAAhRX\nACgw1iSC/fv3p21mZ2cHt2cBackLw2ecbzxwVmt3wvBZwHlubi7tw1npfu/evYPbFxYW0j6c0L3z\nrQhZMP/8+fNpH6dOnUrbLC4uDm53JjwsLS2lbbJz54zVaeNMIsi+/eKGG25I+3DeZ849l3EmALT4\nJoL1+jYDZ1KEiydXAChAcQWAAhRXAChAcQWAAhRXAChAcQWAAhRXAChAcQWAAmMlZvft25e22bZt\n2+D2ixcvpn0cPnw4bXP//fcPbj9y5Ejah7O6ufMNAbt27Rrc7qxu7rTJJmg4xzMxMZG2ya6hlE+u\ncMLlTmA7O7dOH85EkKyNM7GlxeQXKX+POJNSnAky2f3UKlDf4lsrnPvJaZNp9Y0HEk+uAFCC4goA\nBSiuAFCA4goABSiuAFCA4goABSiuAFBgrCDb9PR02mbDhg2D28+cOZP28fnPfz5tc+jQocHtTp7T\nWSx4586daZvsvDh93HzzzWmbLH/qLBDuZAGdbG/Wj7O4sbModzYWZ6zZPem0ce6VVtneLGvZalH0\nLJfrXB/nmJ3zn2mxaL3DyQe7eHIFgAIUVwAoQHEFgAIUVwAoQHEFgAIUVwAoQHEFgAIUVwAoMNYk\nAicYnmmxoK0k3XnnnYPbb7rpprQPJ4DuhMezgLMzQWD//v1pm0uXLg1uf+yxx9I+nONxgu7ZJA1n\n8W8nsJ0dkxN0dyaUZMfc4t53Zdd5ZmYm7WP37t1pm+y+dUL5Tpvs3LW4D9w2LRbudvHkCgAFKK4A\nUIDiCgAFKK4AUIDiCgAFKK4AUIDiCgAFKK4AUGCsSQQtQrpOuPy2225L22Sheyc47gSGL168mLbJ\nJkbcfvvtaR/Oau3ZCvTO8TjnxZnokfXjhPud8WYr6jvXZ2lpKW2T3dvZqv2SN/nCOeZsoodzrzjX\n8PLly4PbnYkTTpvsmFv0IbWpTy2+zeAKnlwBoADFFQAKUFwBoADFFQAKUFwBoADFFQAKUFwBoMBY\nOdf5+fm0TZY127t3b9rHc57znLRNlqN0xurkH50MXjaWbdu2NRlLlulssXCx2ybLdDo5Syc7mp27\nLPsr5VlZh5NhdRZfd2TvIec6OwtQZ9lR5xquV7Z0vRbLdvpw8eQKAAUorgBQgOIKAAUorgBQgOIK\nAAUorgBQgOIKAAUorgBQYKxJBMeOHUvbZAvw7t69O+3j+uuvT9tkkwScxXWdsPzU1FTa5sCBA2vu\nY3FxMW2TnVsnOO4Etp3AfNbGWdDZ2U820cDpw5nE4Zy7Fpzzn13nbLvkTQDIzp2zH+e8tZgU4byf\nnWNejz6u4MkVAApQXAGgAMUVAApQXAGgAMUVAApQXAGgAMUVAApQXAGgwFiTCB555JG0TbZa/rOe\n9ay0j4mJibTNpUuXBre3Wgl/+/btaZtsYoQTqHcC2y1WdHe0mADQIsTutHH6cFaXz8brfFNEdk9K\nbVbdd+4V5xq22I/TpsU3HrQK92cTh1q9hySeXAGgBMUVAApQXAGgAMUVAApQXAGgAMUVAApQXAGg\nwFg51wsXLqRtssVzt27dmvYxOTlpj+mpjkPyMqzOQtdbtmwZ3O4s9Jvlg6U8a+lkMVstIp7ty8mf\ntsoit9DinnPOrXNfOv202E+LcTjXMMvTOvtxssqObLwslg0AT3MUVwAoQHEFgAIUVwAoQHEFgAIU\nVwAoQHEFgAIUVwAoMNYkgk2bNq25jRPKdwLDWZss2C95AXUnDJ8d8+LiYtqHMwEgm2jg9OEsouyE\nurN9tVpoOTv/zj3pXMPsvLRYQFzyFtTO2jjnzbkXsokGzn3gtMnOnfN+bzWWbIKMcw1dPLkCQAGK\nKwAUoLgCQAGKKwAUoLgCQAGKKwAUoLgCQAGKKwAUGCsx60wAyEK6TmD4/Pnza97P9PR02keLALSU\nh7qdbxloEaR2Jk4458WRhdSdiRPOavkTExOD253jafWtCJlWEw2ysTj7ce6n7L51zonzrRWPP/74\n4PZWEwSy/Uj5eJ3jcfHkCgAFKK4AUIDiCgAFKK4AUIDiCgAFKK4AUIDiCgAFKK4AUGCsSQQzMzNr\n3mGrcPn27dvXPJZWweS5ubnB7fPz82kfTug7W6F+69ataR+OFtfImTixsLCQtskmrjjfJuFoER5v\nMRFB8u7LjDNZIWvTIpQv5fe2c++3OrfZMTGJAACe5iiuAFCA4goABSiuAFCA4goABSiuAFCA4goA\nBcbKuTo5yiz/mGU1JWnTpk1pm2wRZSej5+TrnCxmlgt1cqNOLjRbRPzMmTNpH0ePHk3bnD59Om1z\n0003DW53rqFzL2Tnf3Z2Nu3DGUum1f3kZFizfpw+nLxmdl6cY25xPI5W+dMWY3Hx5AoABSiuAFCA\n4goABSiuAFCA4goABSiuAFCA4goABSiuAFBgrEkEGzZsWPMOL1++vOY+JGlpaWnNfTjB/ZMnT6Zt\nssWwnbE6kxWySQRO+P/QoUNpG2ex8ixg7iys7kwAyBbDdkLhTpvseFotrN5iIWynD6dNi0kEzvs5\nW+i61fG0OLetFuWWeHIFgBIUVwAoQHEFgAIUVwAoQHEFgAIUVwAoQHEFgAIUVwAoMNYkghYrrTur\nzzvh5YwT3M/C/5K3uv/Zs2cHtzvfRJBNEJDyiQZOoPvWW29N20xOTqZtNm4cvnWmp6fTPvbt25e2\ncSYaZJzzkq1032oSQYt72wm6Oyv3txhLq28IyKzXuW15PDy5AkABiisAFKC4AkABiisAFKC4AkAB\niisAFKC4AkCB5jnXLGs2NzeX9uEs1pxxso3OYtnOAuFZFrPF8ThjcfKpO3fuTNtMTU2lbbIc6/bt\n29M+nAW1s2Nyso3OfduiDyd/2mIxZqcP577NsrvOMTvvs/XK9jrHnPXDYtkA8DRHcQWAAhRXAChA\ncQWAAhRXAChAcQWAAhRXAChAcQWAAmNNInAWks2CxxcuXEj7cEL3WTDZWSzbCUDv2LEjbbNly5bB\n7U64f+vWrWmb7Jic6zMxMZG2cfrZvHnzmveTLbgt5cFwJ/TthOGze65FEF7yzm0W7m81lqwfZz/O\neyg7/85+nPPWYqFrZ1F0F0+uAFCA4goABSiuAFCA4goABSiuAFCA4goABSiuAFCA4goABcaaRLC4\nuJi2yQLBzur/zgSALOx76dKltA8ndOxMIshs2rQpbeN8Q0AWdHcC3c4EDWe8LSZxtJgA4Kw+7xxz\ntp9WIfYW3+bRKuie7ccZa4uxtAj/Px19cx4VAFxjFFcAKEBxBYACFFcAKEBxBYACFFcAKEBxBYAC\nY+Vcz507l7ZpkVmbn59P27TIAjqLWDuLPmfjdRbCdvK/WXbXybk6GVYnO5pxcq5O/jQ7L841dGSZ\nTue8Ofdci1yos7i0s5/sfmmRyXU4eWdHi3PrHLOLJ1cAKEBxBYACFFcAKEBxBYACFFcAKEBxBYAC\nFFcAKEBxBYACY00icBag3rx585r7OHnyZNrm5ptvHtzuTGZwAujOhIajR4+ueT/OMR87dmxwu3Nu\nt23blrbZtWtX2mZ6enpwuxPodiYatJg44dwLWZDdCbo7ky+c85Ltywnut2jTaj8twv1OHy0W93bu\nJxdPrgBQgOIKAAUorgBQgOIKAAUorgBQgOIKAAUorgBQgOIKAAXGmkQwNTWVtsmC1E5w/NFHH03b\nLC4uDm53QsdOADqbICBJDzzwwOB2ZxV7Z1X+7JidoLvzjQfON07s3LlzcPvs7Gzax8aNY91+q3Ku\noXNesmvk9OF8a0WLMLwTdF+v4L4jm8ThhP+dY3beQ9m++CYCAHiao7gCQAGKKwAUoLgCQAGKKwAU\noLgCQAGKKwAUoLgCQIGxUtzOivpZ8NgJ6Z44cSJtc+HChcHt2TciSN7K/Y888kjapkUw2WmTBead\nELUzocEJ5h86dGhw+/Hjx9M+ZmZm0jbZNx4496RzL2STBJwJDy1WwpfywLxz3zpjySb8ON/g4MiO\n2TkeZ/KL00/2HmkxseUKnlwBoADFFQAKUFwBoADFFQAKUFwBoADFFQAKUFwBoMBYoS4nR5Zl9Jy8\nmtMmy7k6+cdW2bmsTZYnlLxsaXZMO3bsSPtwMp9OFnNubm5w+6lTp9I+zp49m7bZvXv34Pbrr78+\n7cM5/xlnsWynjSO7F1ou6LzW/TjnNsuWtsinuv1k9cl5H7p4cgWAAhRXAChAcQWAAhRXAChAcQWA\nAhRXAChAcQWAAhRXACgw1iQCJ3TfYhKBEwbOFtTetWtX2ocTlndC93fcccfg9gMHDqR9OJMesoCz\nczzZ5AtJOnfuXNpmfn5+cLsT7neC4VNTU4PbWwX3s7G0uD5S/v6Qnj6TBFos7C3l7+elpaU19yF5\n91OL95CLJ1cAKEBxBYACFFcAKEBxBYACFFcAKEBxBYACFFcAKEBxBYACY00icAL1Tqg44wSGH374\n4cHtd91115rHIUmzs7Npm322xN2WAAAE40lEQVT79g1un5mZSftwwstZSDoL9kvS6dOn0zZOPxs3\nDt8627dvT/u47rr87/ZNmzYNbncC6C2C+85+nGvoTBDI2rR4j0n5eJ0JGk5wPzt3Th+t2mRafGvF\nFTy5AkABiisAFKC4AkABiisAFKC4AkABiisAFKC4AkCBsXKuTgYsyy46WdmJiYm0TbZYtrMotGPr\n1q1pmzNnzgxuX1hYSPtwzkuWF5ybm0v7OHv2bNrGyRlni1g7ec4sKyt5C1BnnPu2xaLbTv60RRvn\nnDjH3GJRbmcsWZtW563FeWm1+LrEkysAlKC4AkABiisAFKC4AkABiisAFKC4AkABiisAFKC4AkCB\nsSYROIvRZkFeZ4FkJ1x+8uTJwe2PPvpo2scNN9yQtnHC/dkC1MePH0/7cELSFy9eHNzuXJ9W4f6W\niwqvhXM/rdcEgVb9tHgPORNBssWyW01EyI7HCf871zBbWF3Kz12r6yzx5AoAJSiuAFCA4goABSiu\nAFCA4goABSiuAFCA4goABSiuAFBgrEkELVYMd/pwwvDZNw0cPnw47cOZROAE6rM28/PzaR/ZpAgp\nPy9O6Dv7BgG3TbYv5zpnIXYpD6k7x+x8s0UWQHeC+63u7ey8OKF7ZyzZfeuMtcXEFWcignP+nXsh\nO3ctvp3hCp5cAaAAxRUAClBcAaAAxRUAClBcAaAAxRUAClBcAaDAWDlXZ+HobEHnbLskLS4upm2y\nfN2DDz6Y9nH33XenbZxjzjKSO3fuTPtwsosLCwuD21vlBZ022TGv12Lazlidc5tlS53Fmlssyi3l\n4225oPOQpaWltI1zz7XIubY6/y1zrBmeXAGgAMUVAApQXAGgAMUVAApQXAGgAMUVAApQXAGgAMUV\nAAqMNYmgxWK0zgQBZ6JBFnA+ePBg2seRI0fSNrfcckvaJgsmOxMR9uzZk7bJzouzcLETtJ6cnEzb\nbNmyZXB7iwWqpTww70wQaDGJoNXi3875d/rJOJMrMs5C8Y4WwX3nGjrWawKGxJMrAJSguAJAAYor\nABSguAJAAYorABSguAJAAYorABSguAJAgbFSwk5IPQv3OyHeFoHt+fn5tI/Dhw+nbQ4cOJC2ySZX\nON9E4ITuM855c66hEx7P2jihb2cSQTbeS5curbkPKQ+6t/qWASfc32JfzvnPxuKM1ZnwkI3FmWTg\n7Mdpk71HWn5TAU+uAFCA4goABSiuAFCA4goABSiuAFCA4goABSiuAFCA4goABcaaRHDhwoW0TbZa\nvhP0db7xIOvH2c9XvvKVtM3zn//8tM3MzMzg9unp6bSPbGV/KT//TljeCd07Exqya+SMxZEF0J3A\nvROob7FCvbOfbJKN06bVRITsXnAC9c7xZP20+paHFt8E0eq+lXhyBYASFFcAKEBxBYACFFcAKEBx\nBYACFFcAKEBxBYACY+VcW2TanIye02bz5s1pm8yJEyfSNidPnkzb7NmzZ3D75ORk2keLhX5b5QVb\nLGju9OHkQp02mRYLOrfIp0ptsshODtx5D2XvVee8OVnY7F5wrnGLayi1W/TcwZMrABSguAJAAYor\nABSguAJAAYorABSguAJAAYorABSguAJAgXDCuQCA8fDkCgAFKK4AUIDiCgAFKK4AUIDiCgAFKK4A\nUIDiCgAFKK4AUIDiCgAFKK4AUOD/A9OP+au9r0iTAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119b44160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_faces(imgs, y, names, select_idx):\n",
    "\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    plt.subplot(1, 1, 1, frameon=False, xticks=[], yticks=[])\n",
    "    nside = 10\n",
    "    \n",
    "#     im = np.vstack([np.hstack([Xproj[i, j] for j in range(nside)])\n",
    "#                     for i in range(nside)])\n",
    "    im = imgs[select_idx]\n",
    "    plt.imshow(im, cmap = 'gray')\n",
    "    plt.grid(False)\n",
    "    plt.title(\"name = {}\".format(names[y[select_idx]]),\n",
    "                 size=18)\n",
    "    # Not sure what this line does.\n",
    "#     plt.clim(0, 16)\n",
    "    \n",
    "# with 8 components, the '9' in the second row looks like 3!\n",
    "# Even with 64 components, that '9' is still not clear!\n",
    "plot_faces(lfw_people.images, y, target_names, 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breakout Exercse: Using this data set (the 7 people, each with at least 70 faces to do face recognition)\n",
    "\n",
    "- ### First do training-testing split :\n",
    "\n",
    "    split the sample (X) into two parts -- X_train and X_test.  For now let X_train be the first 1000 images, and X_test be the rest of the images (288).\n",
    "    \n",
    "    Perform PCA and SVM on X_train.  Then project X_test onto the PCA axes, and then use the trained SVM to predict for X_test.\n",
    "    \n",
    "    This is referred to as \"k-fold.\"  Along with \"leave-one-out\", this is another way to test how good your algorithm is before using it in the \"real world\"\n",
    "\n",
    "    (To connect with what we did for classifying digit image: in classify_dig_svm() from Week15-1, we did a (n-1, 1) split; here we do a train-test split or roughly (3:1), otherwise it's the same.  There the return value is y_pred[0], because there is only one element.  Here's it should just be y_pred since it's an array.)\n",
    "\n",
    "\n",
    "- ### Find the success rate by comparing the prediction for X_test and the correct labels/targets for X_test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 50)\n",
      "(288, 50)\n",
      "82.2916666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "Xtrain = X[:1000, ]\n",
    "Xtest = X[1000:, ]\n",
    "# print(X_train.shape)\n",
    "# print(X_test.shape)\n",
    "# ytrain = y[:1000, ]\n",
    "ytrain = y[:1000, ]\n",
    "ytest = y[1000:, ]\n",
    "\n",
    "n_comp = 50\n",
    "pca = PCA(n_comp, whiten = True)\n",
    "\n",
    "# finding pca axes\n",
    "pca.fit(Xtrain)\n",
    "# projecting training data onto pca axes\n",
    "Xtrain_proj = pca.transform(Xtrain)\n",
    "# projecting test data onto pca axes\n",
    "Xtest_proj = pca.transform(Xtest)\n",
    "\n",
    "print(Xtrain_proj.shape)\n",
    "print(Xtest_proj.shape)\n",
    "\n",
    "# ************************************* The SVM Section ********************************\n",
    "\n",
    "# instantiating an SVM classifier\n",
    "clf = svm.SVC(gamma=0.001, C=100.)\n",
    "\n",
    "# apply SVM to training data and draw boundaries.\n",
    "clf.fit(Xtrain_proj, ytrain)\n",
    "# Use SVM-determined boundaries to make\n",
    "# a prediction for the test data point.\n",
    "ypred = clf.predict(Xtest_proj)\n",
    "\n",
    "correct = np.sum(ytest == ypred)\n",
    "        \n",
    "print(correct/288*100)\n",
    "# print(ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision vs. Recall\n",
    "\n",
    "### \"The precision-recall curve shows the tradeoff between precision and recall for different threshold. A high area under the curve represents both high recall and high precision, where high precision relates to a low false positive rate, and high recall relates to a low false negative rate.\n",
    "\n",
    "### Precision (P) is defined as the number of true positives ($T_p$) over the number of true positives plus the number of false positives ($F_p$).\n",
    "\n",
    "### $P = \\frac{T_p}{T_p+F_p}$\n",
    "\n",
    "### Recall (R) is defined as the number of true positives ($T_p$) over the number of true positives plus the number of false negatives ($F_n$).\n",
    "\n",
    "### $R = \\frac{T_p}{T_p + F_n}$\n",
    "\n",
    "### These quantities are also related to the ($F_1$) score, which is defined as the harmonic mean of precision and recall.\n",
    "\n",
    "### $F1 = 2\\frac{P \\times R}{P+R}$\"\n",
    "\n",
    "\n",
    "### Finally,\n",
    "\n",
    "### \"The support is the number of occurrences of each class in y_true.\"\n",
    "\n",
    "(For more details, see\n",
    "\n",
    "http://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html\n",
    "\n",
    "and\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html#sklearn.metrics.precision_recall_fscore_support)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of Week15-3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
